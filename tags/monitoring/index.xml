<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Monitoring on Alexander Bulimov: Production Engineer and Scale Modeller</title>
    <link>//bulimov.me/tags/monitoring/</link>
    <description>Recent content in Monitoring on Alexander Bulimov: Production Engineer and Scale Modeller</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 27 May 2017 00:00:00 +0000</lastBuildDate><atom:link href="//bulimov.me/tags/monitoring/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Вопросы от Дениса</title>
      <link>//bulimov.me/it/user-questions/</link>
      <pubDate>Sat, 27 May 2017 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/user-questions/</guid>
      <description>Пришло письмо от читателя по имени Денис по форме обратной связи. Поскольку никаких данных для связи с ним Денис не оставил, отвечу здесь.
Привожу письмо полностью (надеюсь, автор не против):
Александр, здравствуйте! Не смог найти вашу электропочту, пишу через форму обратной связи вашего домена на рег.ру :)
С огромным удовольствием читаю твой блог, очень жаль, что больше не обновляешь его.
Помоги, пожалуйста, советом. У меня примерно 12 виртуальных серверов с небольшими микросервисами, на каждом из серверов поставил CollectD и StatsD, плюс на отдельном сервере развёрнул go-carbon - whisper - graphite-api - Grafana.</description>
    </item>
    
    <item>
      <title>Открыл код db-checker</title>
      <link>//bulimov.me/it/db-checker/</link>
      <pubDate>Fri, 18 Mar 2016 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/db-checker/</guid>
      <description>Недавно я открыл код еще одного инструмента, который уже около года использую на работе - db-checker.
Началось все с необходимости проводить регулярные проверки логической целостности данных в БД. Проще говоря - гонять мониторингом запросы к базе.
Сначала это была часть проекта, который проверял данные на нашем CDN. Проект этот сразу планировался многопоточным, поэтому написан на Go. Затем мухи были отделены от котлет, и проверка базы выделилась в отдельную сущность, но несколько legacy-моментов осталось.</description>
    </item>
    
    <item>
      <title>Quis custodiet ipsos custodes?</title>
      <link>//bulimov.me/it/who-watch-the-watchmen/</link>
      <pubDate>Fri, 06 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/who-watch-the-watchmen/</guid>
      <description>Кто же устережёт самих сторожей?, или как (и зачем) я мониторю мониторинг. Как вы понимаете, современный сервис мониторинга это очень сложная штука. Некоторые, как Sensu, выносят всю сложность во внешние сервисы, и потому требуют установки и администрирования нескольких компонентов, таких как очередь и база данных.
Остальные реализуют некоторый функционал этих компонентов сами, упрощая администрирование мониторинга, но усложняя его внутреннее устройство. К примеру, для работы Zabbix нужна только база, а очереди и транспорт он реализует сам.</description>
    </item>
    
    <item>
      <title>Logstash и Graphite</title>
      <link>//bulimov.me/it/logstash-graphite/</link>
      <pubDate>Fri, 09 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/logstash-graphite/</guid>
      <description>Недавно читал серию постов от Datadog про сбор метрик, и в частности статью про метрики Nginx (думал, вдруг что-то новое узнаю). Что меня в этой статье зацепило - так это то, что только версия Nginx Plus показывает статистику количества ответов, разделенную по HTTP-кодам. Поскольку я использую перед Nginx балансировщик HAProxy, который не жадный и показывает подробную статистику по кодам ответов для каждого бекенда и фронтенда, я о таком минусе статистики Nginx даже не думал.</description>
    </item>
    
    <item>
      <title>Заметка о Graphite</title>
      <link>//bulimov.me/it/graphite-experience/</link>
      <pubDate>Fri, 25 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/graphite-experience/</guid>
      <description>На первый взгляд, кажется довольно странным, что сейчас, в 2015 году, все до сих пор используют для хранения time series такой старый и «не модный» инструмент, как Graphite. О ужас, о нем даже почти не пишут в твиттере/G+ и он написан на старом будничном Python, а не на популярном сейчас Go (хотя уже частично написан, но об этом потом).
Но все равно многие используют его, и не сильно жалуются.
Экскурс в историю До открытия кода Graphite в 2008 году был вездесущий RRDTool, использовавшийся (и используемый до сих пор) в таких инструментах как Cacti, Munin и еще в куче других.</description>
    </item>
    
    <item>
      <title>Плагин к collectd для сбора метрик Riak CS</title>
      <link>//bulimov.me/it/collectd-riakcs/</link>
      <pubDate>Thu, 17 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/collectd-riakcs/</guid>
      <description>На днях наконец-то дошли руки до модернизации той части мониторинга, которая отвечает за сбор метрик, и набивший оскомину Munin был окончательно заменен на Graphite + CollectD. Теперь воцарилась идиллия - Icinga2 складывает метрики из perfdata в Graphite, и CollectD отправляет все метрики туда же.
Хочется отдельно отметить, что несмотря на то, что изначально CollectD мне не очень понравился (кому может сейчас понравиться Apache-подобный конфиг?), при дальнейшем изучении я был приятно поражен богатством возможностей этого продукта и крайне бережным его отношением к ресурсам наблюдаемой системы.</description>
    </item>
    
    <item>
      <title>Попробуйте Packetbeat</title>
      <link>//bulimov.me/it/try-packetbeat/</link>
      <pubDate>Thu, 28 May 2015 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/try-packetbeat/</guid>
      <description>Вчера в блоге Elasticsearch появилась отличная новость - проект Packetbeat, развиваемый до этого энтузиастами, присоединился к Elastic.
Я уже довольно давно слежу за этим проектом, и теперь, когда можно не беспокоиться о его будущем, хочу о нем рассказать.
Packetbeat это такой инструмент мониторинга, который работает как анализатор сетевых пакетов, парсит различные протоколы (сейчас поддерживаются HTTP, MySQL, PostgreSQL, Redis, Thrift-RPC), получает нужные данные, и отсылает их либо напрямую в Elasticsearch, либо в Redis, из которого данные будет забирать Logstash и класть их все в тот же Elasticsearch.</description>
    </item>
    
    <item>
      <title>Улучшаем сообщения от мониторинга с помощью cAdvisor-companion</title>
      <link>//bulimov.me/it/cadvisor-companion/</link>
      <pubDate>Tue, 21 Apr 2015 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/cadvisor-companion/</guid>
      <description>Слышали ли вы когда-нибудь о такой практике, как &amp;ldquo;Monitoring Events Enrichment&amp;rdquo;? Если вкратце, то это практика наполнения дополнительной информацией сообщений от мониторинга, так что на выяснение причины проблемы уходит меньше времени и телодвижений.
Есть даже контора, которая помогает внедрять эту практику на коммерческой основе, у них на сайте есть неплохие примеры того, что и зачем можно добавить к обычному сообщению от Nagios.
Сама эта идея мне очень нравится, и вот после очередного неинформативного сообщения от мониторинга, которое пришло тогда, когда я был далеко от компьютера, и гласило CheckDockerStats CRITICAL: 91% CPU Used!</description>
    </item>
    
    <item>
      <title>Мониторим Docker-контейнеры с cAdvisor и Nagios/Icinga2</title>
      <link>//bulimov.me/it/check-cadvisor/</link>
      <pubDate>Fri, 20 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/check-cadvisor/</guid>
      <description>После того, как я научился мониторить память в Docker-контейнерах, я решил мониторить еще и нагрузку на CPU. Поскольку это дело не самое тривиальное, и хотелось не писать свой велосипед, а пользоваться чем-то популярным и поддерживаемым, я решил попробовать cAdvisor.
И вот что я могу сказать - отличный инструмент! Ресурсов практически не потребляет (около 20 Мб оперативной памяти и неизмеримо мало CPU), обладает простым API для доступа к собираемой им информации, имеет красивый веб-интерфейс с realtime-графиками.</description>
    </item>
    
    <item>
      <title>Научился мониторить использование памяти в Docker-контейнерах</title>
      <link>//bulimov.me/it/check-docker-memory/</link>
      <pubDate>Fri, 13 Feb 2015 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/check-docker-memory/</guid>
      <description>Я сегодня занимался мониторингом, а конкретно нашими докер-контейнерами.
Лирическое отступление: Для мониторинга я теперь (уже на другом месте работы) использую наследника Nagios - Icinga2. Пока все нравится, ребята очень круто переписали Nagios, реализовали гораздо более вменяемый формат конфигурации, и кучу новых возможностей.
Используя Docker для автотестов я уже ловил проблемы, когда интерпретатор Ruby кушал всю выделенную память в контейнере и тихо умирал от рук OOM Killer.
Поскольку теперь я использую Docker уже не только для тестов, но и &amp;ldquo;в бою&amp;rdquo;, меня сильно беспокоило то, что мы не можем мониторить использование памяти внутри контейнера.</description>
    </item>
    
    <item>
      <title>Удобная настройка Sensu с Ansible</title>
      <link>//bulimov.me/it/ansible-sensu/</link>
      <pubDate>Thu, 13 Nov 2014 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/ansible-sensu/</guid>
      <description>Так как я использую Sensu для мониторинга, и Ansible для управления конфигурациями, то конечно же я настраиваю Sensu с помощью Ansible.
В этой связке меня смущало только одно - Sensu использует JSON для конфигов, в то время как Ansible использует YAML. Поскольку JSON является подмножеством YAML, и описывать конфигурации в YAML гораздо проще (никаких проблем с запятыми, скобочками), хотелось писать в YAML и транслировать в JSON.
Начал я, конечно, с использования шаблонов Ansible:</description>
    </item>
    
    <item>
      <title>Выложил немного полезностей</title>
      <link>//bulimov.me/it/%D0%92%D1%8B%D0%BB%D0%BE%D0%B6%D0%B8%D0%BB-%D0%BD%D0%B5%D0%BC%D0%BD%D0%BE%D0%B3%D0%BE-%D0%BF%D0%BE%D0%BB%D0%B5%D0%B7%D0%BD%D0%BE%D1%81%D1%82%D0%B5%D0%B9/</link>
      <pubDate>Wed, 17 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/%D0%92%D1%8B%D0%BB%D0%BE%D0%B6%D0%B8%D0%BB-%D0%BD%D0%B5%D0%BC%D0%BD%D0%BE%D0%B3%D0%BE-%D0%BF%D0%BE%D0%BB%D0%B5%D0%B7%D0%BD%D0%BE%D1%81%D1%82%D0%B5%D0%B9/</guid>
      <description>Когда я писал про то, как переписал скрипты для Sensu, я слегка слукавил. Изначально, я написал эти скрипты на Python, и только потом на Ruby. Поскольку пользователям других Nagios-совместимых систем мониторинга может показаться неудобным использование ruby-скриптов, да еще и с зависимостью от гема Sensu-plugin, я решил выложить и Python-версии скриптов.
Если кому хочется мониторить состояние дисков в raid-контроллерах от 3ware или HP SmartArray на чистом Python - милости просим, все в моем репозитории.</description>
    </item>
    
    <item>
      <title>Переписал скрипты на Ruby для Sensu</title>
      <link>//bulimov.me/it/%D0%9F%D0%B5%D1%80%D0%B5%D0%BF%D0%B8%D1%81%D0%B0%D0%BB-%D1%81%D0%BA%D1%80%D0%B8%D0%BF%D1%82%D1%8B-%D0%BD%D0%B0-ruby-%D0%B4%D0%BB%D1%8F-sensu/</link>
      <pubDate>Thu, 04 Sep 2014 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/%D0%9F%D0%B5%D1%80%D0%B5%D0%BF%D0%B8%D1%81%D0%B0%D0%BB-%D1%81%D0%BA%D1%80%D0%B8%D0%BF%D1%82%D1%8B-%D0%BD%D0%B0-ruby-%D0%B4%D0%BB%D1%8F-sensu/</guid>
      <description>Поскольку я перевел мониторинг с Zabbix на Sensu, пришлось переписать свои скрипты проверки состояния жестких дисков в raid-контроллерах от 3ware и HP SmartArray для использования в Sensu. Ну а раз все равно переписывать - то писать я решил на Ruby, чтобы можно было без проблем заслать в Sensu-community-plugins
Скрипты весьма просты, так что проблем при переписывании никаких не было.
Если кому надо - все уже отдано сообществу, теперь Sensu может мониторить состояние дисков в контроллерах от 3ware и HP SmartArray.</description>
    </item>
    
    <item>
      <title>Модуль zabbix_maintenance</title>
      <link>//bulimov.me/it/%D0%9C%D0%BE%D0%B4%D1%83%D0%BB%D1%8C-zabbix_maintenance/</link>
      <pubDate>Mon, 11 Aug 2014 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/%D0%9C%D0%BE%D0%B4%D1%83%D0%BB%D1%8C-zabbix_maintenance/</guid>
      <description>Свершилось чудо, и мой модуль для Ansible, который умеет создавать и удалять периоды &amp;ldquo;в обслуживании&amp;rdquo; в Zabbix, наконец-то приняли в апстрим. Это уже третий мой модуль, принятый в апстрим Ansible.
Краткая история:
Модуль этот я запушил еще в 26 ноября 2013 года, но 21 декабря cove написал в комментарии к моему модулю, что планирует выложить целую пачку модулей для взаимодействия с Zabbix из Ansible. Это отложило принятие моего модуля в апстрим почти на 9 месяцев, поскольку мы согласовывали интерфейс наших модулей, тестировали и улучшали модули, выложенные cove, а очередь pull-requestов у Ansible выросла до 300+.</description>
    </item>
    
    <item>
      <title>Низкоуровневое обнаружение в Zabbix, ищем диски в контроллере от 3ware</title>
      <link>//bulimov.me/it/%D0%9D%D0%B8%D0%B7%D0%BA%D0%BE%D1%83%D1%80%D0%BE%D0%B2%D0%BD%D0%B5%D0%B2%D0%BE%D0%B5-%D0%BE%D0%B1%D0%BD%D0%B0%D1%80%D1%83%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5-%D0%B2-zabbix-%D0%B8%D1%89%D0%B5%D0%BC-%D0%B4%D0%B8%D1%81%D0%BA%D0%B8-%D0%B2-%D0%BA%D0%BE%D0%BD%D1%82%D1%80%D0%BE%D0%BB%D0%BB%D0%B5%D1%80%D0%B5-%D0%BE%D1%82-3ware/</link>
      <pubDate>Wed, 14 Aug 2013 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/%D0%9D%D0%B8%D0%B7%D0%BA%D0%BE%D1%83%D1%80%D0%BE%D0%B2%D0%BD%D0%B5%D0%B2%D0%BE%D0%B5-%D0%BE%D0%B1%D0%BD%D0%B0%D1%80%D1%83%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5-%D0%B2-zabbix-%D0%B8%D1%89%D0%B5%D0%BC-%D0%B4%D0%B8%D1%81%D0%BA%D0%B8-%D0%B2-%D0%BA%D0%BE%D0%BD%D1%82%D1%80%D0%BE%D0%BB%D0%BB%D0%B5%D1%80%D0%B5-%D0%BE%D1%82-3ware/</guid>
      <description>Я уже писал про низкоуровневое обнаружение в Zabbix, так что повторять теорию не буду.
Теперь мне понадобилось автоматом получать список хардов в массивах на контроллерах 3ware, которыми оборудованы у нас многие сервера.
Вести руками шаблоны для каждого сервера с иным порядком или количеством дисков показалось мне плохой идеей, да и авто-обнаружение само напрашивалось.
Вдохновлялся я утилитой 3ware-status, для работы авто-обнаружения нам потребуется установленная утилита tw-cli, взять ее для Debian/Ubuntu проще всего здесь .</description>
    </item>
    
    <item>
      <title>Monitoring sucks!</title>
      <link>//bulimov.me/it/monitoring-sucks/</link>
      <pubDate>Wed, 10 Jul 2013 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/monitoring-sucks/</guid>
      <description>TL;DR - тут я Sensu критиковал, но в 2014 году успешно заменил Zabbix на Sensu версии 0.12+
В 2012 году появился в среде devops такой хештег, #monitoringsucks. В сообщения с этим тегом devopsы писали, что текущее положение дел в сфере мониторинга их не устраивает. Что именно - прекрасно иллюстрирует эта презентация Если вкратце - хочется людям некоего стандарта API для взаимодействия между компонентами утилит мониторинга, ну и появления самих этих компонент, чтоб из них строить гибкий и умный мониторинг.</description>
    </item>
    
    <item>
      <title>Низкоуровневое обнаружение в Zabbix</title>
      <link>//bulimov.me/it/%D0%9D%D0%B8%D0%B7%D0%BA%D0%BE%D1%83%D1%80%D0%BE%D0%B2%D0%BD%D0%B5%D0%B2%D0%BE%D0%B5-%D0%BE%D0%B1%D0%BD%D0%B0%D1%80%D1%83%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5-%D0%B2-zabbix/</link>
      <pubDate>Wed, 26 Jun 2013 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/%D0%9D%D0%B8%D0%B7%D0%BA%D0%BE%D1%83%D1%80%D0%BE%D0%B2%D0%BD%D0%B5%D0%B2%D0%BE%D0%B5-%D0%BE%D0%B1%D0%BD%D0%B0%D1%80%D1%83%D0%B6%D0%B5%D0%BD%D0%B8%D0%B5-%D0%B2-zabbix/</guid>
      <description>В используемой мной системе мониторинга Zabbix, начиная с версии 2.0, появилась такая любопытная штука, как низкоуровневое обнаружение
Я не буду пересказывать содержимое документации, расскажу лучше о том, как я писал свой тип обнаружения для мониторинга очередей RabbitMQ.
Проблема в том, что очередей в RabbitMQ может быть много, и, по мере развития веб-проекта, они меняются. Так что я решил обнаруживать их автоматически, и написал для этого свой провайдер данных для обнаружения заббикса.</description>
    </item>
    
  </channel>
</rss>
