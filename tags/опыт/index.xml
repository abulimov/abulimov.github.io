<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Опыт on Alexander Bulimov: Production Engineer and Scale Modeller</title>
    <link>//bulimov.me/tags/%D0%BE%D0%BF%D1%8B%D1%82/</link>
    <description>Recent content in Опыт on Alexander Bulimov: Production Engineer and Scale Modeller</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 08 Feb 2016 00:00:00 +0000</lastBuildDate><atom:link href="//bulimov.me/tags/%D0%BE%D0%BF%D1%8B%D1%82/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Замена carbon-cache на go-carbon = Счастье</title>
      <link>//bulimov.me/it/go-carbon/</link>
      <pubDate>Mon, 08 Feb 2016 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/go-carbon/</guid>
      <description>Пришлось на собственном опыте опробовать, насколько Graphite модульный.
При 200k metricsReceived наш Graphite, работающий на довольном старом сервере на обычных дисках, начал помирать. Carbon-cache постоянно был в топе потребления ресурсов, ни о какой отзывчивости в работе сервера речи вообще не шло.
&amp;ldquo;Хватит это терпеть!&amp;rdquo; - подумал я, и начал в который раз искать советы по тюнингу carbon для высокой производительности. В очередной раз ничего нового не найдя, я решил попробовать давно приглянувшийся мне проект go-carbon.</description>
    </item>
    
    <item>
      <title>Немного житейского опыта</title>
      <link>//bulimov.me/it/productivity-tips/</link>
      <pubDate>Tue, 12 Jan 2016 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/productivity-tips/</guid>
      <description>Решил поделиться небольшим набором &amp;ldquo;капитанских&amp;rdquo; жизненных практик, каждая из которых очень сильно упростила мне жизнь.
Использование сервиса для чтения новостей/RSS.
Я очень долго игнорировал RSS, считая его пережитком прошлого, но когда создавал свой VPS, поставил TT-RSS и попробовал попользоваться.
Сложно даже описать, сколько это мне сэкономило времени. Это оказалось настолько удобно, что теперь я не представляю свою жизнь без подобного сервиса, хоть от tt-rss и отказался вместе с VPS.
Теперь я избавлен от необходимости запоминать и время от времени обходить все интересные мне блоги, никогда не пропускаю новости и обновления софта, и всегда могу без проблем наверстать пропущенные (например в отпуске) события.</description>
    </item>
    
    <item>
      <title>Quis custodiet ipsos custodes?</title>
      <link>//bulimov.me/it/who-watch-the-watchmen/</link>
      <pubDate>Fri, 06 Nov 2015 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/who-watch-the-watchmen/</guid>
      <description>Кто же устережёт самих сторожей?, или как (и зачем) я мониторю мониторинг. Как вы понимаете, современный сервис мониторинга это очень сложная штука. Некоторые, как Sensu, выносят всю сложность во внешние сервисы, и потому требуют установки и администрирования нескольких компонентов, таких как очередь и база данных.
Остальные реализуют некоторый функционал этих компонентов сами, упрощая администрирование мониторинга, но усложняя его внутреннее устройство. К примеру, для работы Zabbix нужна только база, а очереди и транспорт он реализует сам.</description>
    </item>
    
    <item>
      <title>Избавился от CoreOS</title>
      <link>//bulimov.me/it/goodby-coreos/</link>
      <pubDate>Mon, 26 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/goodby-coreos/</guid>
      <description>С огромным облегчением сегодня убрал последний хост с CoreOS.
Я уже писал о своих впечатлениях от CoreoOS, но с тех пор впечатлений прибавилось.
Частые атомарные обновления на бумаге выглядели вкусно (и в пользовательских ОС типа Android работают прекрасно), но вот на практике на серверах в том виде, в котором CoreOS их готовит, оказались совсем несъедобны.
Объясню, в чем проблема: Docker достаточно часто что-то ломает в API, и свежие ядра Linux ломают всякие важные вещи тоже довольно часто, причем зачастую даже в рамках patch-level обновлений.</description>
    </item>
    
    <item>
      <title>Logstash и Graphite</title>
      <link>//bulimov.me/it/logstash-graphite/</link>
      <pubDate>Fri, 09 Oct 2015 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/logstash-graphite/</guid>
      <description>Недавно читал серию постов от Datadog про сбор метрик, и в частности статью про метрики Nginx (думал, вдруг что-то новое узнаю). Что меня в этой статье зацепило - так это то, что только версия Nginx Plus показывает статистику количества ответов, разделенную по HTTP-кодам. Поскольку я использую перед Nginx балансировщик HAProxy, который не жадный и показывает подробную статистику по кодам ответов для каждого бекенда и фронтенда, я о таком минусе статистики Nginx даже не думал.</description>
    </item>
    
    <item>
      <title>Заметка о Graphite</title>
      <link>//bulimov.me/it/graphite-experience/</link>
      <pubDate>Fri, 25 Sep 2015 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/graphite-experience/</guid>
      <description>На первый взгляд, кажется довольно странным, что сейчас, в 2015 году, все до сих пор используют для хранения time series такой старый и «не модный» инструмент, как Graphite. О ужас, о нем даже почти не пишут в твиттере/G+ и он написан на старом будничном Python, а не на популярном сейчас Go (хотя уже частично написан, но об этом потом).
Но все равно многие используют его, и не сильно жалуются.
Экскурс в историю До открытия кода Graphite в 2008 году был вездесущий RRDTool, использовавшийся (и используемый до сих пор) в таких инструментах как Cacti, Munin и еще в куче других.</description>
    </item>
    
    <item>
      <title>Использование ELK в продакшне</title>
      <link>//bulimov.me/it/elk-production/</link>
      <pubDate>Tue, 11 Aug 2015 00:00:00 +0000</pubDate>
      
      <guid>//bulimov.me/it/elk-production/</guid>
      <description>Я уже довольно давно и успешно использую Logstash + Elasticsearch с визуализацией данных в Kibana (общепринятое сокращение для этой тройки - ELK) для сбора, хранения и обработки логов, но для обретения счастья с этой связкой мне потребовалось несколько итераций.
Поскольку в мире СПО все постоянно развивается и становится лучше, сразу хочу отметить, что все описанное актуально для Logstash версиий 1.4-1.5 и Elasticsearch версий 1.4 - 1.7 при нагрузке в ~20kk сообщений в день.</description>
    </item>
    
  </channel>
</rss>
